{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subodh_pushkar/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/subodh_pushkar/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "#import warnings\n",
    "#warnings.simplefilter('ignore')\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage\n",
    "import skimage.exposure\n",
    "# import mahotas as mh\n",
    "from sklearn.cross_validation import KFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, \\\n",
    "    Convolution2D, MaxPooling2D, ZeroPadding2D, Input, Embedding, LSTM, merge, \\\n",
    "    Lambda, UpSampling2D, Deconvolution2D, Cropping2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_IOU_gpu(X, Y):\n",
    "    \"\"\"Computes mean Intersection-over-Union (IOU) for two arrays of binary images.\n",
    "    Assuming X and Y are of shape (n_images, w, h).\"\"\"\n",
    "    \n",
    "    #X_fl = K.clip(K.batch_flatten(X), K.epsilon(), 1.)\n",
    "    #Y_fl = K.clip(K.batch_flatten(Y), K.epsilon(), 1.)\n",
    "    X_fl = K.clip(K.batch_flatten(X), 0., 1.)\n",
    "    Y_fl = K.clip(K.batch_flatten(Y), 0., 1.)\n",
    "    X_fl = K.cast(K.greater(X_fl, 0.5), 'float32')\n",
    "    Y_fl = K.cast(K.greater(Y_fl, 0.5), 'float32')\n",
    "\n",
    "    intersection = K.sum(X_fl * Y_fl, axis=1)\n",
    "    union = K.sum(K.maximum(X_fl, Y_fl), axis=1)\n",
    "    # if union == 0, it follows that intersection == 0 => score should be 0.\n",
    "    union = K.switch(K.equal(union, 0), K.ones_like(union), union)\n",
    "    return K.mean(intersection / K.cast(union, 'float32'))\n",
    "\n",
    "\n",
    "def mean_IOU_gpu_loss(X, Y):\n",
    "    return -mean_IOU_gpu(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    # Workaround for shape bug. For some reason y_true shape was not being set correctly\n",
    "    #y_true.set_shape(y_pred.get_shape())\n",
    "\n",
    "    # Without K.clip, K.sum() behaves differently when compared to np.count_nonzero()\n",
    "    #y_true_f = K.clip(K.batch_flatten(y_true), K.epsilon(), 1.)\n",
    "    #y_pred_f = K.clip(K.batch_flatten(y_pred), K.epsilon(), 1.)\n",
    "    y_true_f = K.clip(K.batch_flatten(y_true), 0., 1.)\n",
    "    y_pred_f = K.clip(K.batch_flatten(y_pred), 0., 1.)\n",
    "    #y_pred_f = K.greater(y_pred_f, 0.5)\n",
    "\n",
    "    intersection = 2 * K.sum(y_true_f * y_pred_f, axis=1)\n",
    "    union = K.sum(y_true_f * y_true_f, axis=1) + K.sum(y_pred_f * y_pred_f, axis=1)\n",
    "    return K.mean(intersection / union)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice(y_true, y_pred)\n",
    "\n",
    "\n",
    "def log_dice_loss(y_true, y_pred):\n",
    "    return -K.log(dice(y_true, y_pred))\n",
    "\n",
    "\n",
    "def dice_metric(y_true, y_pred):\n",
    "    \"\"\"An exact Dice score for binary tensors.\"\"\"\n",
    "    y_true_f = K.cast(K.greater(y_true, 0.5), 'float32')\n",
    "    y_pred_f = K.cast(K.greater(y_pred, 0.5), 'float32')\n",
    "    return dice(y_true_f, y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# from losses import *\n",
    "\n",
    "def get_unet_128(input_shape=(128, 128, 3),\n",
    "                 num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # 128\n",
    "\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(inputs)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = LeakyReLU(alpha=0.15)(down1)\n",
    "    down1 = Conv2D(64, (3, 3), padding='same')(down1)\n",
    "    down1 = BatchNormalization()(down1)\n",
    "    down1 = LeakyReLU(alpha=0.15)(down1)\n",
    "    down1_pool = MaxPooling2D((2, 2), strides=(2, 2))(down1)\n",
    "    # 64\n",
    "\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down1_pool)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = LeakyReLU(alpha=0.15)(down2)\n",
    "    down2 = Conv2D(128, (3, 3), padding='same')(down2)\n",
    "    down2 = BatchNormalization()(down2)\n",
    "    down2 = LeakyReLU(alpha=0.15)(down2)\n",
    "    down2_pool = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n",
    "    # 32\n",
    "\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down2_pool)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = LeakyReLU(alpha=0.15)(down3)\n",
    "    down3 = Conv2D(256, (3, 3), padding='same')(down3)\n",
    "    down3 = BatchNormalization()(down3)\n",
    "    down3 = LeakyReLU(alpha=0.15)(down3)\n",
    "    down3_pool = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n",
    "    # 16\n",
    "\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down3_pool)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = LeakyReLU(alpha=0.15)(down4)\n",
    "    down4 = Conv2D(512, (3, 3), padding='same')(down4)\n",
    "    down4 = BatchNormalization()(down4)\n",
    "    down4 = LeakyReLU(alpha=0.15)(down4)\n",
    "    down4_pool = MaxPooling2D((2, 2), strides=(2, 2))(down4)\n",
    "    # 8\n",
    "\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(down4_pool)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = LeakyReLU(alpha=0.15)(center)\n",
    "    center = Conv2D(1024, (3, 3), padding='same')(center)\n",
    "    center = BatchNormalization()(center)\n",
    "    center = LeakyReLU(alpha=0.15)(center)\n",
    "    # center\n",
    "\n",
    "    up4 = UpSampling2D((2, 2))(center)\n",
    "    up4 = concatenate([down4, up4], axis=3)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = LeakyReLU(alpha=0.15)(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = LeakyReLU(alpha=0.15)(up4)\n",
    "    up4 = Conv2D(512, (3, 3), padding='same')(up4)\n",
    "    up4 = BatchNormalization()(up4)\n",
    "    up4 = Activation('relu')(up4)\n",
    "    # 16\n",
    "\n",
    "    up3 = UpSampling2D((2, 2))(up4)\n",
    "    up3 = concatenate([down3, up3], axis=3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = LeakyReLU(alpha=0.15)(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = LeakyReLU(alpha=0.15)(up3)\n",
    "    up3 = Conv2D(256, (3, 3), padding='same')(up3)\n",
    "    up3 = BatchNormalization()(up3)\n",
    "    up3 = LeakyReLU(alpha=0.15)(up3)\n",
    "    # 32\n",
    "\n",
    "    up2 = UpSampling2D((2, 2))(up3)\n",
    "    up2 = concatenate([down2, up2], axis=3)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = LeakyReLU(alpha=0.15)(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = LeakyReLU(alpha=0.15)(up2)\n",
    "    up2 = Conv2D(128, (3, 3), padding='same')(up2)\n",
    "    up2 = BatchNormalization()(up2)\n",
    "    up2 = LeakyReLU(alpha=0.15)(up2)\n",
    "    # 64\n",
    "\n",
    "    up1 = UpSampling2D((2, 2))(up2)\n",
    "    up1 = concatenate([down1, up1], axis=3)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = LeakyReLU(alpha=0.15)(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = LeakyReLU(alpha=0.15)(up1)\n",
    "    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n",
    "    up1 = BatchNormalization()(up1)\n",
    "    up1 = LeakyReLU(alpha=0.15)(up1)\n",
    "    # 128\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid')(up1)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss=log_dice_loss,\n",
    "              metrics=[mean_IOU_gpu, dice_metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 36928       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  147584      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 256)  590080      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 256)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 512)  2359808     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 512)    0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 1024)   4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 1024)   4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 1024)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 1024)   9438208     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 1024)   4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 1024)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 1024) 0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 1536) 0           leaky_re_lu_8[0][0]              \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 512)  7078400     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 512)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 768)  0           leaky_re_lu_6[0][0]              \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 256)  1769728     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 256)  590080      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 32, 32, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 64, 256)  0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 384)  0           leaky_re_lu_4[0][0]              \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  442496      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 128)  147584      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 64, 64, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 128, 128, 128 0           leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 192 0           leaky_re_lu_2[0][0]              \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 64) 110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 128, 64) 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 64) 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 64) 36928       leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 64) 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 128, 128, 64) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 1)  65          leaky_re_lu_21[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 34,540,737\n",
      "Trainable params: 34,527,041\n",
      "Non-trainable params: 13,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_unet_128()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import *\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('dataset/crop/RIM-ONEv2/images/*.jpg')              #change '/'\n",
    "X = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "# filelist = glob.glob('dataset/crop/RIM-ONEv1/images/*.jpg')              #change '/'\n",
    "# X = np.concatenate((X,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# filelist = glob.glob('dataset/crop/DRIONS_DB/images/*.jpg')              #change '/'\n",
    "# X = np.concatenate((X,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# filelist = glob.glob('dataset/crop/DRISHTI_GS/images/*.jpg')              #change '/'\n",
    "# X = np.concatenate((X,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# filelist = glob.glob('dataset/crop/RIM-ONEv3/images/*.jpg')              #change '/'\n",
    "# X = np.concatenate((X,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# X=X.reshape(841,3,128,128)\n",
    "print(X.shape)\n",
    "# X = np.concatenate((glu,nonglu),axis=0)\n",
    "# print(X.shape)\n",
    "# print(X[1,:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('dataset/crop/RIM-ONEv2/discs/*.png')              #change '/'\n",
    "Y = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "# filelist = glob.glob('dataset/crop/RIM-ONEv1/discs/*.png')              #change '/'\n",
    "# Y = np.concatenate((Y,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# filelist = glob.glob('dataset/crop/DRIONS_DB/discs/*.png')              #change '/'\n",
    "# Y = np.concatenate((Y,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# filelist = glob.glob('dataset/crop/DRISHTI_GS/discs/*.png')              #change '/'\n",
    "# Y = np.concatenate((Y,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "# filelist = glob.glob('dataset/crop/RIM-ONEv3/discs/*.png')              #change '/'\n",
    "# Y = np.concatenate((Y,[np.array(Image.open(fname)) for fname in filelist]),axis=0)\n",
    "Y = Y.reshape(455,128,128,1)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "\n",
    "for i in range(455):\n",
    "    X[i,:,:,:] = (X[i,:,:,:] - np.min(X[i,:,:,:])) / (np.max(X[i,:,:,:]) - np.min(X[i,:,:,:]))\n",
    "    Y[i,:,:,:] = (Y[i,:,:,:] - np.min(Y[i,:,:,:])) / (np.max(Y[i,:,:,:]) - np.min(Y[i,:,:,:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 128, 128, 3) (60, 128, 128, 3) (335, 128, 128, 1) (60, 128, 128, 1) (60, 128, 128, 3) (60, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#SplittingTheData\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.20, random_state=42)\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.13, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape,X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subodh_pushkar/anaconda3/lib/python3.5/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#CallBackFunc\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "callbacks = [EarlyStopping(monitor='val_loss',\n",
    "                           patience=8,\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=4,\n",
    "                               verbose=1,\n",
    "                               epsilon=1e-4),\n",
    "             ModelCheckpoint(monitor='val_loss',\n",
    "                             filepath='weights/best_weights.hdf5',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True),\n",
    "TensorBoard(log_dir='logs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.load_weights('weights/best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 335 samples, validate on 60 samples\n",
      "Epoch 1/15\n",
      "335/335 [==============================] - 500s 1s/step - loss: 0.0818 - mean_IOU_gpu: 0.8221 - dice_metric: 0.8996 - val_loss: 0.1006 - val_mean_IOU_gpu: 0.7861 - val_dice_metric: 0.8780\n",
      "Epoch 2/15\n",
      "335/335 [==============================] - 495s 1s/step - loss: 0.0734 - mean_IOU_gpu: 0.8366 - dice_metric: 0.9087 - val_loss: 0.0903 - val_mean_IOU_gpu: 0.8031 - val_dice_metric: 0.8889\n",
      "Epoch 3/15\n",
      "335/335 [==============================] - 494s 1s/step - loss: 0.0721 - mean_IOU_gpu: 0.8396 - dice_metric: 0.9104 - val_loss: 0.0989 - val_mean_IOU_gpu: 0.7925 - val_dice_metric: 0.8820\n",
      "Epoch 4/15\n",
      "335/335 [==============================] - 495s 1s/step - loss: 0.0712 - mean_IOU_gpu: 0.8402 - dice_metric: 0.9109 - val_loss: 0.1094 - val_mean_IOU_gpu: 0.7643 - val_dice_metric: 0.8641\n",
      "Epoch 5/15\n",
      "335/335 [==============================] - 495s 1s/step - loss: 0.0717 - mean_IOU_gpu: 0.8391 - dice_metric: 0.9103 - val_loss: 0.1130 - val_mean_IOU_gpu: 0.7723 - val_dice_metric: 0.8684\n",
      "Epoch 6/15\n",
      "335/335 [==============================] - 493s 1s/step - loss: 0.0641 - mean_IOU_gpu: 0.8548 - dice_metric: 0.9196 - val_loss: 0.0956 - val_mean_IOU_gpu: 0.7931 - val_dice_metric: 0.8823\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 7/15\n",
      "335/335 [==============================] - 490s 1s/step - loss: 0.0601 - mean_IOU_gpu: 0.8641 - dice_metric: 0.9250 - val_loss: 0.0914 - val_mean_IOU_gpu: 0.7998 - val_dice_metric: 0.8867\n",
      "Epoch 8/15\n",
      "335/335 [==============================] - 486s 1s/step - loss: 0.0541 - mean_IOU_gpu: 0.8753 - dice_metric: 0.9317 - val_loss: 0.0933 - val_mean_IOU_gpu: 0.7978 - val_dice_metric: 0.8854\n",
      "Epoch 9/15\n",
      "335/335 [==============================] - 488s 1s/step - loss: 0.0516 - mean_IOU_gpu: 0.8811 - dice_metric: 0.9350 - val_loss: 0.0990 - val_mean_IOU_gpu: 0.7880 - val_dice_metric: 0.8793\n",
      "Epoch 10/15\n",
      "335/335 [==============================] - 489s 1s/step - loss: 0.0508 - mean_IOU_gpu: 0.8830 - dice_metric: 0.9360 - val_loss: 0.1006 - val_mean_IOU_gpu: 0.7871 - val_dice_metric: 0.8786\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "H = model.fit(X_train, y_train, batch_size=8, epochs=epochs, verbose=1,\n",
    "              callbacks=callbacks,validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 25s 420ms/step\n",
      "[0.10616323600212733, 0.7919622133175532, 0.8795565485954284]\n",
      "loss= 0.10616323600212733\n",
      "metric 0.7919622133175532 0.8795565485954284\n"
     ]
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, epochs=1, batch_size=1,shuffle=True,callbacks=callbacks,validation_data=(X_val, y_val))\n",
    "scores = model.evaluate(X_test, y_test, batch_size=1, steps=None)\n",
    "print(scores)\n",
    "print('loss=',scores[0])\n",
    "print('metric',scores[1],scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:log_dice_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7508f8809d25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Returns a compiled model identical to the previous one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/second_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    288\u001b[0m                           \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                           \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                           sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                     printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 165\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:log_dice_loss"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save('models/second_model.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "model = load_model('models/second_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(H.history['loss'])\n",
    "plt.plot(H.history['val_loss'])\n",
    "plt.title('Training for ' +str(10)+ ' epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0a8dbf16939a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training for '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m' epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Validation accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(H.history['acc'])\n",
    "plt.plot(H.history['val_acc'])\n",
    "plt.title('Training for ' +str(10)+ ' epochs')\n",
    "plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
